# 인공지능

- 개요
  - SW. 지능적인 행동의 자동화. 인간의 지능적, 반복적인 행동을 수행
  - 인공지능의 90% 이상은 지도학습(Supervised Learning)
  - 인공지능에 대한 스스로 똑똑해지거나 감정을 가질 수 없음

- 기타
  - 모라벡의 역설 : 사람에게 쉬운것이 기계에게 어렵고, 기계에게 어려운것이 사람에게 쉽다.
  - 배경 : 이미 이론은 있었음 양질의 데이터를 확보할 수 있는 환경과 GPU를 넘는 TPU칩 등의 하드웨어 환경이 갖춰짐
  - 2차원 matrix, 다차원 tensor
    - 차원 = 채널 = depth
  - 유명한 이미지 인식 대회(ImageNet Large Scale Visual Recognition Competition)의 AlexNet이 CNN의 전환기
  - 도메인 적응 문제 : 추론 환경이 다르면 AI는 제 기능을 수행하지 못함

- 강인공지능 : 스스로 판단하고 결정하는 영화에서 말하는 인공지능
  - 범용성을 가지는 범인공지능
- 약인공지능 : 제한된 환경의 특정 업무 수행을 위한 인공지능
  - 알파고, 서빙로봇 같은 특화. 범용성의 폭이 좁음

- 인공지능 > 머신러닝 > 딥러닝
  - 머신러닝 : 데이터로부터 패턴을 기계가 스스로 학습
  - 딥러닝 : 인공신경망 기반. 비정형 raw에서부터 특징 추출과 판단까지 수행

- 정형데이터(structure) : 안정성. 체계적. 구조고정.
  - 머신러닝기반의 빅데이터 분석기법: R, SAS, SPSS 등의 통계분석 틀
  - 예시
    - 선형/로지스틱 회귀분석을 통한 실수 예측
    - 의사결정나무를 통한 카테고리분류
    - ARMA, ARIMA 모형을 통한 시계열 예측
- 비정형데이터 : 다양한 형식. 텍스트, 음성, 이미지, 영상.
  - 생산 데이터의 대다수고 비율이 계속 증가
  - 딥러닝 기반의 데이터 처리

- 인공신경망(Artificial Neural Network) : 인간처럼 기계에게 사례를 통한 학습을 시켜보자
  - 인공뉴런 : 데이터를 받아 가중합 연산을 하여 다음 인공뉴런으로 데이터를 넘김
  - 인공뉴런을 여럿 쌓아 인공신경망을 만들어 인간의 사고방식을 재현
  - 기계가 특징을 파악하여 분류를 수행
- CNN(Convolutional Neural Network) : 이미지처리를 위한 특별한 인공신경망 구성 방식
  - 특징 추출(Feature Extraction) 영역 + 태스크 수행 영역
    - 특징 추출
      - 컨볼루션 연산을 통한 이미지 특징 추출 및 Feature map 도출
      - 풀링 연산 : Feature map에서 핵심 정보 sampling
        - 주로 가장 큰 값만을 가져오는 max pool 방식
    - 태스크 수행 : 대표적 예시 몇 가지
      - Classification : 입력 이미지를 K개의 클래스(카테고리)로 분류
      - Detection : 특정 개체의 위치와 좌표값을 네모박스 단위로 찾아 줌
      - Segmentation : 개체를 픽셀 단위로 찾고 영역을 구별

- 자연어이해(NLU;Natural Language Understanding/Processing)
  - 인공어 : 자연어 반댓말 의도와 목적에 따라 만들어진 언어. 프로그래밍 언어. 기계 언어. 에스페란토.
  - 이해 : 맥락 내용의 파악. 규칙에 따른 수행인 처리(Processing)보다 고차원
  - Tokenizing : 한 덩이 문장을 인공신경망이 인식할 수 있는 세부단위로 Parsing
    - 목적에 따라 어절, 형태소, 음절(교착어인 한국어에 적당), 자소 등 여러 방식으로 나뉨
  - 워드임베딩 : 토큰을 벡터화
    - 원-핫 인코딩 : 단어대로 번호를 붙임(이때 숫자간 우열은 없음)
    - CBOW와 SKIPGRAM : 문맥을 통해 단어의 뜻을 알아내는 알고리즘. 벡터길이가 원핫인코딩보다 훨씬 작음(51만->300)
      - CBOW : 문장에 빈칸을 만들어 단어(토큰)를 유추시킴
      - SKIPGRAM : 단어를 하나 알려주고 주위에 등장할만한 문맥을 만들게 함
  - 과제
    - 문장/문서분류
    - Sequence-to-Sequence : 번역, 요약
    - 질의 응답 : IR(Information Retrieval) : 과거 유사답변, MRC : 매뉴얼 내 가능성 높은 영역을 반환

- 시계열데이터 처리
  - 순환신경망(RNN; Recurrent Neural Network) : 과거 데이터 처리 과정일부를 가져와 현 시점에 반영하는 인공신경망
    - 벡터 형태로 정보(feature)를 넘김. 정보의 누적이 인코딩, 결과의 출력이 디코딩
    - 장점 : 과거 정보 반영, 가변길이 데이터 처리, 다양한 구조로 구출
    - 단점 : 느림, 불안정한 학습, 폭발적 학습량 증가(Gradient Exploding), 여러번 압축된 과거 정보의 활용(Gradient Vanishing)
    - 성능보완(Long-Short Term Memory) : forget(잊어버림), input(현재 정보), output(나중에 얼마나 쓸지) / GRU와 유사

- AI 도입 과정
  - Offline Process : Training Pipeline. 데이터 가공, 정제, 라벨링
    - 튜닝 : 좋은 성능이 나올때까지 반복 실험, 하이퍼파라미터 설정
    - model : Validate&Select > Train > Publish(최종 선택)
  - Online Process : 추론 하여 실제환경에서 운영
  - 주의사항 : 훈련시 데이터에만 잘 작동하는 Overfitting
    - Training, Validation, Test 추천 비율; 8:1:1, 6:2:2
    - Regularization : 일반화 성능을 향상시켜 Overfitting 개선하는 기법
      - 데이터 증강 : 반전, 크롭, 노이즈, 색상, 명암, 채도 등으로 데이터를 늘림
      - Capacity : 모델 복잡 정도. 늘리면 학습을 잘하다 못해 암기해버림
      - 조기 종료 : 학습 곡선이 어느 정도 올라가면 학습을 종료해버림
      - 드롭 아웃 : 교육시 몇몇 인공 뉴런을 종료해버림
